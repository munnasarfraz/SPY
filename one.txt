def run_comparison(extract_to_temp=False):
    source1_zips = list_zip_files(source_1_prefix)
    source2_zips = list_zip_files(source_2_prefix)

    source1_csv_map = {}
    source2_csv_map = {}

    build_csv_to_zip_map(source1_zips, 'downloads/source1', source1_csv_map)
    build_csv_to_zip_map(source2_zips, 'downloads/source2', source2_csv_map)

    common_csvs = list(set(source1_csv_map) & set(source2_csv_map))
    missing_in_source2 = set(source1_csv_map) - set(source2_csv_map)
    missing_in_source1 = set(source2_csv_map) - set(source1_csv_map)

    # Extract if needed
    if extract_to_temp:
        print("ðŸ“¦ Extracting ZIPs to disk once...")
        source1_csv_map = extract_all_zips(source1_csv_map, 'downloads/source1/extract')
        source2_csv_map = extract_all_zips(source2_csv_map, 'downloads/source2/extract')

    print(f"ðŸ”„ Reading and comparing {len(common_csvs)} CSV files in parallel (batch size: {BATCH_SIZE})...")

    queue = mp.Queue(maxsize=cpu_count() * 2)
    manager = Manager()
    output_list = manager.list()

    with tqdm(total=len(common_csvs), desc="Overall Progress", ncols=100) as overall_pbar, \
         tqdm(total=len(common_csvs), desc="Reading Progress", ncols=100) as read_pbar, \
         tqdm(total=len(common_csvs), desc="Comparing Progress", ncols=100) as compare_pbar:

        processes = []
        for _ in range(cpu_count()):
            p = Process(target=compare_worker, args=(queue, output_list, compare_pbar, overall_pbar))
            p.start()
            processes.append(p)

        with ThreadPoolExecutor(max_workers=32) as executor:
            futures = [
                executor.submit(
                    reader_batch_thread,
                    chunk,
                    source1_csv_map,
                    source2_csv_map,
                    queue,
                    read_pbar,
                    overall_pbar,
                    extract=extract_to_temp  # ðŸ‘ˆ pass the flag here
                )
                for chunk in chunk_list(common_csvs, BATCH_SIZE)
            ]
            for f in futures:
                f.result()

        for _ in range(cpu_count()):
            queue.put(SENTINEL)
        for p in processes:
            p.join()

    # Collect results
    all_diffs = []
    all_summaries = {}
    for csv_name, diff_df, summary in output_list:
        if not diff_df.empty:
            diff_df['File'] = csv_name
            all_diffs.append(diff_df)
        all_summaries[csv_name] = summary

    if missing_in_source2:
        all_summaries["Missing CSVs in Source2"] = list(missing_in_source2)
    if missing_in_source1:
        all_summaries["Extra CSVs in Source2"] = list(missing_in_source1)

    final_diff_df = pd.concat(all_diffs) if all_diffs else pd.DataFrame()
    return final_diff_df, all_summaries, [len(source1_csv_map), len(source2_csv_map)]
